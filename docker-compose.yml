services:
  pdb-server:
    build:
      context: ./protein-data-bank-mcp
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "8080:8080"
  chembl-server:
    build:
      context: ./chembl-mcp
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "8081:8081"

  ollama:
    image: ollama/ollama:latest
    runtime: nvidia
    env_file:
      - .env.docker
    environment:
      - OLLAMA_MODELS=/.ollama/models
    ports:
      - "11435:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ollama_models:/.ollama

  llm-client:
    build:
      context: ./llm-client
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - "8000:8000"
    depends_on:
      - ollama
      - pdb-server
      - chembl-server
    environment:
      - OLLAMA_HOST=ollama
      - PDB_MCP_HOST=pdb-server
      - CHEMBL_MCP_HOST=chembl-server

volumes:
  ollama_models:
    driver: local
    driver_opts:
      type: none
      device: /usr/share/ollama/.ollama
      o: bind
